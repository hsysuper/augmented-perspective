{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AugmentedPerspective.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNNtYSyZprarGcF7TLqk1wq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Augmented Perspective"],"metadata":{"id":"Ff_p9Bf11V7z"}},{"cell_type":"markdown","source":["This iPython Notebook runs the the Augmented Perspective experiment flow"],"metadata":{"id":"wD9Uus9o1tUL"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)\n","\n","# enter the foldername in your Drive where your augmented perspective repo is checked out\n","# e.g. 'projects/augmented-perspective':\n","# if FOLDERNAME, current directory of the iPython notebook will be used\n","FOLDERNAME = 'CS231A/augmented-perspective'\n","\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","%cd drive/My\\ Drive\n","%cd $FOLDERNAME"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghLx0JWF1hcE","executionInfo":{"status":"ok","timestamp":1647222572734,"user_tz":420,"elapsed":2261,"user":{"displayName":"Jack He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii2cyDuzWK9j1sgxhEv-i1DhZ3F-Wydi8sVylSQ-Y=s64","userId":"10039646587119707053"}},"outputId":"1dc5b033-5c59-480b-b950-425d941ea9cb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive\n","/content/drive/.shortcut-targets-by-id/1g15eqMB8VyviBypnBlOVm8H-tu-OksvO/augmented-perspective\n"]}]},{"cell_type":"markdown","source":["Then, you should be able to run the following with no problem."],"metadata":{"id":"ERgToM2s3N9S"}},{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2\n","\n","import importlib\n","import sys\n","\n","# pre-import everything to save time\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from skimage import io\n","import torch\n","\n","!nvidia-smi \n","device = 'cpu'\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","    torch.cuda.empty_cache() \n","print(\"Using {} for computation\".format(device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GXUBu5dD3PDR","executionInfo":{"status":"ok","timestamp":1647222574306,"user_tz":420,"elapsed":1576,"user":{"displayName":"Jack He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii2cyDuzWK9j1sgxhEv-i1DhZ3F-Wydi8sVylSQ-Y=s64","userId":"10039646587119707053"}},"outputId":"8b12d1bd-6b4d-4487-a65e-bc908bae1a55"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Mar 14 01:49:34 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Using cuda for computation\n"]}]},{"cell_type":"code","source":["# try import project libraries\n","import augmented_perspective\n","import calibration\n","import depth_model"],"metadata":{"id":"WgsUG0jG7qOY","executionInfo":{"status":"ok","timestamp":1647222574914,"user_tz":420,"elapsed":610,"user":{"displayName":"Jack He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii2cyDuzWK9j1sgxhEv-i1DhZ3F-Wydi8sVylSQ-Y=s64","userId":"10039646587119707053"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Run the depth model with GPU againsts assets/kitti2.png"],"metadata":{"id":"ycID7_sB4Esd"}},{"cell_type":"code","source":["importlib.reload(depth_model)\n","argv = [\"runner.py\", \"--image_path\", \"assets/kitti2.png\", \"--device\", device]\n","depth_model.run_depth_model(argv)\n","original_image = io.imread(\"assets/kitti2.png\")\n","depth_image_after_monodepth2 = io.imread(\"outputs/kitti2_monodepth2_depth.png\")\n","depth_map_after_monodepth2 = np.load(\"outputs/kitti2_monodepth2_depth.npy\")\n","print(\"Depth Map Size After Monodepth:{}\".format(depth_map_after_monodepth2.shape))\n","depth_image_after_boosting = io.imread(\"outputs/kitti2_boosting_depth.png\")\n","depth_map_after_boosting = np.load(\"outputs/kitti2_boosting_depth.npy\")\n","print(\"Depth Map Size After Boosting:{}\".format(depth_map_after_boosting.shape))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3kU027Xe51Py","executionInfo":{"status":"error","timestamp":1647222637363,"user_tz":420,"elapsed":62451,"user":{"displayName":"Jack He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii2cyDuzWK9j1sgxhEv-i1DhZ3F-Wydi8sVylSQ-Y=s64","userId":"10039646587119707053"}},"outputId":"7b7d0a3f-ca9d-4bad-b52b-d75823dac1b4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["before ['/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py', '-f', '/root/.local/share/jupyter/runtime/kernel-a70086d0-cb26-4da2-bf8c-8ea78e401960.json']\n","after ['runner.py', '--image_path', 'assets/kitti2.png', '--device', 'cuda']\n","Namespace(boosting=True, device='cuda', image_files=['kitti2.png'], image_path='../../assets', model_name='mono_1024x320', monodepth2=True, output_path='../../outputs/')\n","-> Loading model from  models/mono_1024x320\n","   Loading pretrained encoder\n","   Loading pretrained decoder\n","Reading images from ../../assets\n","-> Predicting on 1 test images\n","input_image.shape:  torch.Size([1, 3, 320, 1024])\n","disp.shape:  torch.Size([1, 1, 320, 1024])\n","disp_resized.shape:  torch.Size([1, 1, 370, 1224])\n","scaled_disp.shape:  torch.Size([1, 1, 320, 1024])\n","[[4.9915996 5.091959  5.1896105 ... 3.1745822 3.1612873 3.1302292]\n"," [5.0030622 5.1008735 5.1998634 ... 3.168944  3.1556315 3.1273923]\n"," [5.007049  5.097818  5.19861   ... 3.1896892 3.1729252 3.1429288]\n"," ...\n"," [1.812802  1.815973  1.8119583 ... 1.7320216 1.7306013 1.7260487]\n"," [1.803794  1.8066583 1.8028905 ... 1.7183156 1.7166754 1.711133 ]\n"," [1.7973248 1.7993972 1.7960956 ... 1.709864  1.7082198 1.7020305]]\n","disp_resized_np.shape:  (370, 1224)\n","   Processed 1 of 1 images - saved predictions to:\n","   - ../../outputs/kitti2_monodepth2_depth.png\n","   - ../../outputs/kitti2_monodepth2_disp.npy\n","-> Done!\n","Reading images from ../../assets\n","device: cuda\n","----------------- Options ---------------\n","                    Final: False                         \n","             aspect_ratio: 1.0                           \n","                 boosting: False                         \n","          checkpoints_dir: ./pix2pix/checkpoints         \n","         colorize_results: False                         \n","                crop_size: 672                           \n","             dataset_mode: depthmerge                    \n","                   device: cuda                          \t[default: cpu]\n","                direction: AtoB                          \n","                    epoch: latest                        \n","                     eval: False                         \n","                  gpu_ids: -1                            \n","               image_path: assets/kitti2.png             \t[default: assets/]\n","                init_gain: 0.02                          \n","                init_type: normal                        \n","                 input_nc: 2                             \n","                  isTrain: False                         \t[default: None]\n","                load_iter: 0                             \t[default: 0]\n","                load_size: 672                           \n","                  max_res: inf                           \n","                    model: pix2pix4depth                 \n","               monodepth2: False                         \n","               n_layers_D: 3                             \n","                     name: void                          \n","                      ndf: 64                            \n","                     netD: basic                         \n","                     netG: unet_1024                     \n"," net_receptive_field_size: None                          \n","                      ngf: 64                            \n","               no_dropout: False                         \n","                     norm: none                          \n","                 num_test: 50                            \n","                output_nc: 1                             \n","              output_path: outputs/                      \n","                    phase: test                          \n","              pix2pixsize: None                          \n","               preprocess: resize_and_crop               \n","                  verbose: False                         \n","----------------- End -------------------\n","initialize network with normal\n","loading the model from ./pix2pix/checkpoints/mergemodel/latest_net_G.pth\n","Loading weights:  midas/model.pt\n"]},{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_main\n"]},{"output_type":"stream","name":"stdout","text":["start processing\n","processing image 0 : kitti2\n","\t wholeImage being processed in : 1920\n"," \t \t DEBUG| GPU THRESHOLD REACHED 1920 ---> 1568\n","Adjust factor is: 1.3008887614678901\n","Selecting patchs ...\n","Target resolution:  (1510, 4995, 3)\n","Dynamicly change merged-in resolution; scale: 0.24503311258278146\n","\t Resulted depthmap res will be : (370, 1224)\n","patchs to process: 29\n","\t processing patch 0 | [  2   2 329 329]\n","\t processing patch 1 | [ 73   2 329 329]\n","\t processing patch 2 | [143   2 329 329]\n","\t processing patch 3 | [214   2 329 329]\n","\t processing patch 4 | [284   2 329 329]\n","\t processing patch 5 | [355   2 329 329]\n","\t processing patch 6 | [425   2 329 329]\n","\t processing patch 7 | [496   2 329 329]\n","\t processing patch 8 | [107 107 259 259]\n","\t processing patch 9 | [177 107 259 259]\n","\t processing patch 10 | [248 107 259 259]\n","\t processing patch 11 | [319 107 259 259]\n","\t processing patch 12 | [389 107 259 259]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-c26f02f160cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"runner.py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--image_path\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"assets/kitti2.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--device\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdepth_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_depth_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moriginal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"assets/kitti2.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdepth_image_after_monodepth2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"outputs/kitti2_monodepth2_depth.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1g15eqMB8VyviBypnBlOVm8H-tu-OksvO/augmented-perspective/depth_model.py\u001b[0m in \u001b[0;36mrun_depth_model\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_cp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser_cp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mchange_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./models/{name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_depth_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1g15eqMB8VyviBypnBlOVm8H-tu-OksvO/augmented-perspective/depth_model.py\u001b[0m in \u001b[0;36mget_depth_map\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_depth_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mboosting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_depth_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \"\"\"\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1g15eqMB8VyviBypnBlOVm8H-tu-OksvO/augmented-perspective/models/boosting/depth_prediction.py\u001b[0m in \u001b[0;36mget_depth_map\u001b[0;34m(option, parser)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;31m# field size of the network for patches to accelerate the process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             patch_estimation = doubleestimate(patch_rgb, option.net_receptive_field_size, option.patch_netsize,\n\u001b[0;32m--> 171\u001b[0;31m                                               option.pix2pixsize)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             patch_estimation = cv2.resize(patch_estimation, (option.pix2pixsize, option.pix2pixsize),\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1g15eqMB8VyviBypnBlOVm8H-tu-OksvO/augmented-perspective/models/boosting/depth_prediction.py\u001b[0m in \u001b[0;36mdoubleestimate\u001b[0;34m(img, size1, size2, pix2pixsize)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;31m# Inference on the merge model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mpix2pixmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimate1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimate2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0mpix2pixmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0mvisuals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpix2pixmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_visuals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0mprediction_mapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisuals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fake_B'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1g15eqMB8VyviBypnBlOVm8H-tu-OksvO/augmented-perspective/models/boosting/pix2pix/models/base_model.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_visuals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1g15eqMB8VyviBypnBlOVm8H-tu-OksvO/augmented-perspective/models/boosting/pix2pix/models/pix2pix4depth_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;34m\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# G(A)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1g15eqMB8VyviBypnBlOVm8H-tu-OksvO/augmented-perspective/models/boosting/pix2pix/models/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;34m\"\"\"Standard forward\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1g15eqMB8VyviBypnBlOVm8H-tu-OksvO/augmented-perspective/models/boosting/pix2pix/models/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutermost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# add skip connections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1g15eqMB8VyviBypnBlOVm8H-tu-OksvO/augmented-perspective/models/boosting/pix2pix/models/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# add skip connections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    923\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    924\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["plt.rcParams.update({'font.size': 6})\n","f, ax = plt.subplots(1, 3, dpi=500)\n","ax[0].imshow(original_image)\n","ax[0].title.set_text('RGB')\n","ax[1].imshow(depth_image_after_monodepth2)\n","ax[1].title.set_text('Monodepth2')\n","ax[2].imshow(depth_image_after_boosting)\n","ax[2].title.set_text('Boosting')"],"metadata":{"id":"pLcbfZNBGXVB","executionInfo":{"status":"aborted","timestamp":1647222637360,"user_tz":420,"elapsed":4,"user":{"displayName":"Jack He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii2cyDuzWK9j1sgxhEv-i1DhZ3F-Wydi8sVylSQ-Y=s64","userId":"10039646587119707053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.rcParams.update({'font.size': 6})\n","f, ax = plt.subplots(1, 3, dpi=500)\n","ax[0].imshow(original_image)\n","ax[0].title.set_text('RGB')\n","ax[1].imshow(depth_map_after_monodepth2, cmap='gray')\n","ax[1].title.set_text('Monodepth2')\n","ax[2].imshow(depth_map_after_boosting, cmap='gray')\n","ax[2].title.set_text('Boosting')"],"metadata":{"id":"GYxI7gR9nOcp","executionInfo":{"status":"aborted","timestamp":1647222637361,"user_tz":420,"elapsed":5,"user":{"displayName":"Jack He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii2cyDuzWK9j1sgxhEv-i1DhZ3F-Wydi8sVylSQ-Y=s64","userId":"10039646587119707053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run the augmented perspective code againsts assets/kitti2.png"],"metadata":{"id":"z6wGxc8UNokM"}},{"cell_type":"code","source":["importlib.reload(augmented_perspective)\n","argv = [\"runner.py\", \"--image_path\", \"assets/kitti2.png\", \"--depth_map_path\", \"outputs/kitti2_monodepth2_depth.npy\"]\n","augmented_perspective.run_augmented_perspective(argv)\n","reprojected_image_after_monodepth2 = io.imread(\"output_images/kitti2_monodepth2_depth_reprojected.png\")\n","\n","argv = [\"runner.py\", \"--image_path\", \"assets/kitti2.png\", \"--depth_map_path\", \"outputs/kitti2_boosting_depth.npy\"]\n","augmented_perspective.run_augmented_perspective(argv)\n","reprojected_image_after_boosting = io.imread(\"output_images/kitti2_boosting_depth_reprojected.png\")\n"],"metadata":{"id":"wb0sZ_kg9Qb2","executionInfo":{"status":"aborted","timestamp":1647222637362,"user_tz":420,"elapsed":5,"user":{"displayName":"Jack He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii2cyDuzWK9j1sgxhEv-i1DhZ3F-Wydi8sVylSQ-Y=s64","userId":"10039646587119707053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.rcParams.update({'font.size': 6})\n","f, ax = plt.subplots(1, 3, dpi=500)\n","ax[0].imshow(original_image)\n","ax[0].title.set_text('RGB')\n","ax[1].imshow(reprojected_image_after_monodepth2)\n","ax[1].title.set_text('Monodepth2')\n","ax[2].imshow(reprojected_image_after_boosting)\n","ax[2].title.set_text('Boosting')"],"metadata":{"id":"gV6AVak0OqbN","executionInfo":{"status":"aborted","timestamp":1647222637362,"user_tz":420,"elapsed":5,"user":{"displayName":"Jack He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii2cyDuzWK9j1sgxhEv-i1DhZ3F-Wydi8sVylSQ-Y=s64","userId":"10039646587119707053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def draw_histogram(ax, data):\n","    counts, bins = np.histogram(data)\n","    ax.hist(bins[:-1], bins, weights=counts)\n","\n","f, ax = plt.subplots(1, 2, dpi=500)\n","draw_histogram(ax[0], depth_map_after_monodepth2)\n","ax[0].title.set_text('Monodepth2')\n","draw_histogram(ax[1], depth_map_after_boosting)\n","ax[1].title.set_text('Boosting')"],"metadata":{"id":"GSSYS5VB_NUZ","executionInfo":{"status":"aborted","timestamp":1647222637362,"user_tz":420,"elapsed":5,"user":{"displayName":"Jack He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii2cyDuzWK9j1sgxhEv-i1DhZ3F-Wydi8sVylSQ-Y=s64","userId":"10039646587119707053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raw_depth_map_after_monodepth2 = np.load(\"outputs/kitti2_monodepth2_resized_disp.npy\")\n","raw_depth_map_after_boosting = np.load(\"outputs/kitti2_boosting_depth_raw.npy\")\n","inverse_depth_map_after_boosting = np.load(\"outputs/kitti2_boosting_depth_inverse.npy\")\n","\n","f, ax = plt.subplots(1, 3, dpi=500)\n","draw_histogram(ax[0], raw_depth_map_after_monodepth2)\n","ax[0].title.set_text('Monodepth2 Raw')\n","draw_histogram(ax[1], raw_depth_map_after_boosting)\n","ax[1].title.set_text('Boosting Raw')\n","draw_histogram(ax[2], inverse_depth_map_after_boosting)\n","ax[2].title.set_text('Boosting Inverse')"],"metadata":{"id":"4hlCF4zXEWnO","executionInfo":{"status":"aborted","timestamp":1647222637363,"user_tz":420,"elapsed":6,"user":{"displayName":"Jack He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii2cyDuzWK9j1sgxhEv-i1DhZ3F-Wydi8sVylSQ-Y=s64","userId":"10039646587119707053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now run this against all images in asset/ folder"],"metadata":{"id":"PGj0W1aoj8RU"}},{"cell_type":"code","source":["import os\n","importlib.reload(depth_model)\n","argv = [\"runner.py\", \"--image_path\", \"assets/\", \"--device\", device]\n","depth_model.run_depth_model(argv)"],"metadata":{"id":"B6X9wmcQj8BV","executionInfo":{"status":"aborted","timestamp":1647222637363,"user_tz":420,"elapsed":6,"user":{"displayName":"Jack He","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii2cyDuzWK9j1sgxhEv-i1DhZ3F-Wydi8sVylSQ-Y=s64","userId":"10039646587119707053"}}},"execution_count":null,"outputs":[]}]}